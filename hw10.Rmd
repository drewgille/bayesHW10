---
title: "hw10"
output: html_document
date: "2024-04-21"
---

# 2

```{r}
library(tidyr)
library(dplyr)
library(ggplot2)
```


```{r}
Y <- readRDS("birdCount.rds")
Y <- as.data.frame(Y)
Y.grouped <- Y%>%
  group_by(county)%>%
  summarize(sum = sum(birdCount))
sum.y <- Y.grouped$sum
Y.grouped2 <- Y%>%
  group_by(county)%>%
  filter(birdCount != 0)%>%
  summarize(length = n())
n <- Y.grouped2$length


```


```{r}
#initialize
alpha <- 10
a <- 2
b <- 1/2
THETA <- NULL
MU <- NULL
mu <- mean(sum.y/n)

#Gibbs
S <- 100
for (s in 1:S){
  
  #sample thetas
  theta <- c(rep(0, 16))
  for(j in 1:16){
    theta[j] <- rgamma(1, alpha+sum.y[j], n[j]+alpha/mu)
  }
  
  #sample mu
  inv.mu <- rgamma(1, a, b+(alpha)*sum(theta))
  mu <- 1/inv.mu
  
  #store
  
  THETA <- cbind(THETA, theta)
  MU <- cbind(MU, mu)
  
  
  
  
}
```

```{r}
plot(density(MU))
x <- 0:10000
gam <- dgamma(x, a, b)
inv.gam <- 1/gam
lines(x, inv.gam, type="l", col="red", lwd=2)
```
```{r}
plot(x, inv.gam, type="l")
```

```{r}
theta.means <- rowMeans(THETA)
df <- data.frame(n, theta.means)
ggplot(df, aes(x=n, y=theta.means))+
  geom_point()+
  geom_smooth()
```

```{r}
sample.means <- sum.y/n
df2 <- data.frame(n, sample.means)
ggplot(df, aes(x=n, y=sample.means))+
  geom_point()+
  geom_smooth()
```

```{r}
distance <- sample.means - theta.means
df3 <- data.frame(n, distance)
ggplot(df, aes(x=n, y=distance))+
  geom_point()+
  geom_smooth()
```
As we can see in this last graph, as sample size gets bigger, a county's estimate of $\theta_j$ gets closer to its sample mean $\overline{y}_j$.


# 3

```{r}
#Gibbs

delta.prior <- c(0.45, 0.1, 0.45)
mu.delta <- c(-3, 0, 3)
sigma2.delta <- c(1/3, 1/3, 1/3)
delta <- sample(1:3, size = 1, prob = delta.prior)
THETA <- NULL
DELTA <- NULL
S <- 10000

for (s in 1:S){
  #generate theta
  theta <- rnorm(1, mu.delta[delta], sqrt(sigma2.delta[delta]))
  
  #generate delta
  delta.post <- rep(0, 3)
  for (i in 1:3) {
    delta.post[i] <- delta.prior[i] * dnorm(theta, mean = mu.delta[i], sd = sqrt(sigma2.delta[i]))
  }
  delta.post <- delta.post/sum(delta.post)
  delta <- sample(1:3, size = 1, prob = delta.post)
  
  #store values
  THETA[s] <- theta
  DELTA[s] <- delta
  
}
```

```{r}
# Metropolis

delta.prior <- c(0.45, 0.1, 0.45)
mu.delta <- c(-3, 0, 3)
sigma2.delta <- c(1/3, 1/3, 1/3)
THETA.m <- NULL
DELTA.m <- NULL
delta <- sample(1:3, size = 1, prob = delta.prior)
theta <- rnorm(1, mu.delta[delta], sqrt(sigma2.delta[delta]))
S <- 10000

for (s in 1:S){
  
  #generate theta
  theta <- rnorm(1, mu.delta[delta], sqrt(sigma2.delta[delta]))
  
  #simulate theta.star
  theta.star <- rnorm(1, theta, 2)

  
  #generate delta
  delta.post <- rep(0, 3)
  for (i in 1:3) {
    delta.post[i] <- delta.prior[i] * dnorm(theta, mean = mu.delta[i], sd = sqrt(sigma2.delta[i]))
  }
  delta.post <- delta.post/sum(delta.post)
  delta <- sample(1:3, size = 1, prob = delta.post)
  
  
  
    #compute Metropolis ratio
  log.r <- sum((dnorm(delta, theta.star, sqrt(sigma2.delta[delta]), log = TRUE)) +
    dnorm(theta.star, mu.delta[delta], 2, log = TRUE)) -
    sum((dnorm(delta, theta, sqrt(sigma2.delta[delta]), log = TRUE)) +
    dnorm(theta, mu.delta[delta], 2, log = TRUE))
  
  if(log(runif(1)) < log.r){
    theta <- theta.star
  }
  
  
  THETA.m <- c(THETA.m, theta)
  DELTA.m <- c(DELTA.m, delta)
  
  
}
```

```{r}
#traceplots
plot(THETA, type="l")
plot(THETA.m, type="l")
```
```{r}
acf(THETA)
acf(THETA.m)
```
The acf plot for the Metropolis algorithm converges quicker than that of the original Gibbs sampler.

```{r}
library(coda)
effectiveSize(THETA)
effectiveSize(THETA.m)
```
The effective sample size for the Metropolis algorithm Gibbs sampler is greater than that of the original Gibbs sampler.

```{r}
hist(THETA, freq=FALSE, breaks=20)
hist(THETA.m, freq=FALSE, breaks=20)
```
The first histogram is heavier towards THETA==-3, whereas the second is more symmetric.
