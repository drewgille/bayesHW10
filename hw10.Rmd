---
title: "hw10"
output: html_document
date: "2024-04-21"
---

# 1

```{r}
yX <- dget(url("http://www2.stat.duke.edu/~pdh10/FCBS/Inline/yX.o2uptake"))
y <- yX[,1]
X <- yX[,-1]
g <- length(y)
nu0 <- 1
s20 <- 8.54
```

```{r}
lpy.X<-function(y,X,
   g=length(y),nu0=1,s20=try(summary(lm(y~-1+X))$sigma^2,silent=TRUE)) 
{
  n<-dim(X)[1] ; p<-dim(X)[2] 
  if(p==0){
    s20<-mean(y^2)
    }
  H0<-0 ; if(p>0) { H0<- (g/(g+1)) * X%*%solve(t(X)%*%X)%*%t(X) }
  SS0<- t(y)%*%( diag(1,nrow=n)  - H0 ) %*%y

  -.5*n*log(2*pi) +lgamma(.5*(nu0+n)) - lgamma(.5*nu0)  - .5*p*log(1+g) +
   .5*nu0*log(.5*nu0*s20) -.5*(nu0+n)*log(.5*(nu0*s20+SS0))
}
```

```{r}
lz1 <- -44.33
lz12 <- lpy.X(y, X[,c(1,2)])
lz13 <- lpy.X(y, X[,c(1,3)])
lz14 <- lpy.X(y, X[,c(1,4)])
lz123 <- lpy.X(y, X[,c(1,2,3)])
lz124 <- lpy.X(y, X[,c(1,2,4)])
lz134 <- lpy.X(y, X[,c(1,3,4)])
lz1234 <- lpy.X(y, X[,c(1,2,3,4)])

lz1
lz12
lz13
lz14
lz123
lz124
lz134
lz1234
```

```{r}

sum.elz <- exp(lz1)+exp(lz12)+exp(lz13)+exp(lz14)+exp(lz123)+exp(lz124)+exp(lz134)+exp(lz1234)
sum.elz

pz1 <- exp(lz1)/sum.elz
pz12 <- exp(lz12)/sum.elz
pz13 <- exp(lz13)/sum.elz
pz14 <- exp(lz14)/sum.elz
pz123 <- exp(lz123)/sum.elz
pz124 <- exp(lz124)/sum.elz
pz134 <- exp(lz134)/sum.elz
pz1234 <- exp(lz1234)/sum.elz

pz1
pz12
pz13
pz14
pz123
pz124
pz134
pz1234
```
```{r}
lmax <- lz123
dz1 <- lz1 - lmax
dz12 <- lz12 - lmax
dz13 <- lz13 - lmax
dz14 <- lz14 - lmax
dz123 <- lz123 - lmax
dz124 <- lz124 - lmax
dz134 <- lz134 - lmax
dz1234 <- lz1234 - lmax

dz1
dz12
dz13
dz14
dz123
dz124
dz134
dz1234
```

```{r}
sum.e.dpluslmax <- exp(dz1+lmax)+exp(dz12+lmax)+exp(dz13+lmax)+exp(dz14+lmax)+exp(dz123+lmax)+exp(dz124+lmax)+exp(dz134+lmax)+exp(dz1234+lmax)
sum.e.dpluslmax

exp(dz1+lmax)/sum.e.dpluslmax
exp(dz12+lmax)/sum.e.dpluslmax
exp(dz13+lmax)/sum.e.dpluslmax
exp(dz14+lmax)/sum.e.dpluslmax
exp(dz123+lmax)/sum.e.dpluslmax
exp(dz124+lmax)/sum.e.dpluslmax
exp(dz134+lmax)/sum.e.dpluslmax
exp(dz1234+lmax)/sum.e.dpluslmax
```
Same as previous calculation.


# 2

```{r}
library(tidyr)
library(dplyr)
library(ggplot2)
```


```{r}
Y <- readRDS("birdCount.rds")
Y <- as.data.frame(Y)
Y.grouped <- Y%>%
  group_by(county)%>%
  summarize(sum = sum(birdCount))
sum.y <- Y.grouped$sum
Y.grouped2 <- Y%>%
  group_by(county)%>%
  filter(birdCount != 0)%>%
  summarize(length = n())
n <- Y.grouped2$length


```


```{r}
#initialize
alpha <- 10
a <- 2
b <- 1/2
THETA <- NULL
MU <- NULL
mu <- mean(sum.y/n)

#Gibbs
S <- 100
for (s in 1:S){
  
  #sample thetas
  theta <- c(rep(0, 16))
  for(j in 1:16){
    theta[j] <- rgamma(1, alpha+sum.y[j], n[j]+alpha/mu)
  }
  
  #sample mu
  inv.mu <- rgamma(1, a, b+(alpha)*sum(theta))
  mu <- 1/inv.mu
  
  #store
  
  THETA <- cbind(THETA, theta)
  MU <- cbind(MU, mu)
  
  
  
  
}
```

```{r}
plot(density(MU))
x <- 0:10000
gam <- dgamma(x, a, b)
inv.gam <- 1/gam
lines(x, inv.gam, type="l", col="red", lwd=2)
```
```{r}
plot(x, inv.gam, type="l")
```

```{r}
theta.means <- rowMeans(THETA)
df <- data.frame(n, theta.means)
ggplot(df, aes(x=n, y=theta.means))+
  geom_point()+
  geom_smooth()
```

```{r}
sample.means <- sum.y/n
df2 <- data.frame(n, sample.means)
ggplot(df, aes(x=n, y=sample.means))+
  geom_point()+
  geom_smooth()
```

```{r}
distance <- sample.means - theta.means
df3 <- data.frame(n, distance)
ggplot(df, aes(x=n, y=distance))+
  geom_point()+
  geom_smooth()
```
As we can see in this last graph, as sample size gets bigger, a county's estimate of $\theta_j$ gets closer to its sample mean $\overline{y}_j$.


# 3

```{r}
#Gibbs

delta.prior <- c(0.45, 0.1, 0.45)
mu.delta <- c(-3, 0, 3)
sigma2.delta <- c(1/3, 1/3, 1/3)
delta <- sample(1:3, size = 1, prob = delta.prior)
THETA <- NULL
DELTA <- NULL
S <- 10000

for (s in 1:S){
  #generate theta
  theta <- rnorm(1, mu.delta[delta], sqrt(sigma2.delta[delta]))
  
  #generate delta
  delta.post <- rep(0, 3)
  for (i in 1:3) {
    delta.post[i] <- delta.prior[i] * dnorm(theta, mean = mu.delta[i], sd = sqrt(sigma2.delta[i]))
  }
  delta.post <- delta.post/sum(delta.post)
  delta <- sample(1:3, size = 1, prob = delta.post)
  
  #store values
  THETA[s] <- theta
  DELTA[s] <- delta
  
}
```

```{r}
# Metropolis

delta.prior <- c(0.45, 0.1, 0.45)
mu.delta <- c(-3, 0, 3)
sigma2.delta <- c(1/3, 1/3, 1/3)
THETA.m <- NULL
DELTA.m <- NULL
delta <- sample(1:3, size = 1, prob = delta.prior)
theta <- rnorm(1, mu.delta[delta], sqrt(sigma2.delta[delta]))
S <- 10000

for (s in 1:S){
  
  #generate theta
  theta <- rnorm(1, mu.delta[delta], sqrt(sigma2.delta[delta]))
  
  #simulate theta.star
  theta.star <- rnorm(1, theta, 2)

  
  #generate delta
  delta.post <- rep(0, 3)
  for (i in 1:3) {
    delta.post[i] <- delta.prior[i] * dnorm(theta, mean = mu.delta[i], sd = sqrt(sigma2.delta[i]))
  }
  delta.post <- delta.post/sum(delta.post)
  delta <- sample(1:3, size = 1, prob = delta.post)
  
  
  
    #compute Metropolis ratio
  log.r <- sum((dnorm(delta, theta.star, sqrt(sigma2.delta[delta]), log = TRUE)) +
    dnorm(theta.star, mu.delta[delta], 2, log = TRUE)) -
    sum((dnorm(delta, theta, sqrt(sigma2.delta[delta]), log = TRUE)) +
    dnorm(theta, mu.delta[delta], 2, log = TRUE))
  
  if(log(runif(1)) < log.r){
    theta <- theta.star
  }
  
  
  THETA.m <- c(THETA.m, theta)
  DELTA.m <- c(DELTA.m, delta)
  
  
}
```

```{r}
#traceplots
plot(THETA, type="l")
plot(THETA.m, type="l")
```
```{r}
acf(THETA)
acf(THETA.m)
```
The acf plot for the Metropolis algorithm converges quicker than that of the original Gibbs sampler.

```{r}
library(coda)
effectiveSize(THETA)
effectiveSize(THETA.m)
```
The effective sample size for the Metropolis algorithm Gibbs sampler is greater than that of the original Gibbs sampler.

```{r}
hist(THETA, freq=FALSE, breaks=20)
hist(THETA.m, freq=FALSE, breaks=20)
```
The first histogram is heavier towards THETA==-3, whereas the second is more symmetric.
